{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+2bZNaWXaynpw9lvgdVtE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mittalsharad/NLP/blob/main/NLP_Basics/Stop%20Word%20Removal/Stop%20Word%20Removal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw4Km9Ei6brY"
      },
      "source": [
        "# Stop Word Removal using NLTK "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jepYcxf35qUV",
        "outputId": "059b659b-94e9-4b9a-f077-70c2eb830d43"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
        "\n",
        "print(\"Original Tokens: \",text_tokens)\n",
        "print(\"Tokens after StopWord Removal: \",tokens_without_sw)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Tokens:  ['Nick', 'likes', 'to', 'play', 'football', ',', 'however', 'he', 'is', 'not', 'too', 'fond', 'of', 'tennis', '.']\n",
            "Tokens after StopWord Removal:  ['Nick', 'likes', 'play', 'football', ',', 'however', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5n5hfpq6s28"
      },
      "source": [
        "In the script above, we first import the stopwords collection from the nltk.corpus module. Next, we import the word_tokenize() method from the nltk.tokenize class. We then create a variable text, which contains a simple sentence. The sentence in the text variable is tokenized (divided into words) using the word_tokenize() method. Next, we iterate through all the words in the text_tokens list and checks if the word exists in the stop words collection or not. If the word doesn't exist in the stopword collection, it is returned and appended to the tokens_without_sw list. The tokens_without_sw list is then printed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bojPYxAaBBAl"
      },
      "source": [
        "#### **Adding or Removing Stop Words in NLTK's Default Stop Word List**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOrHCE0lA3lP",
        "outputId": "e71b607f-f2ff-4769-b832-5d9c28ac5a06"
      },
      "source": [
        "print(stopwords.words('english'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l8OGHjBe2g"
      },
      "source": [
        "###### **Adding Stop Words to Default NLTK Stop Word List**\n",
        "\n",
        "To add a word to NLTK stop words collection, first create an object from the stopwords.words('english') list. Next, use the append() method on the list to add any word to the list.\n",
        "\n",
        "The following script adds the word play to the NLTK stop word collection. Again, we remove all the words from our text variable to see if the word play is removed or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4eOYVU6BK-y",
        "outputId": "cac38dab-6563-49f3-95cb-26f6f20c6dcf"
      },
      "source": [
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.append('play')\n",
        "\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'football', ',', 'however', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCk1PVssBzVD"
      },
      "source": [
        "The output shows that the word play has been removed.\n",
        "\n",
        "You can also add a list of words to the stopwords.words list using the append method, as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L1eXCZpBtFG",
        "outputId": "6239f5f3-0920-4e9b-d08f-b72ab6bc1e56"
      },
      "source": [
        "sw_list = ['likes','play']\n",
        "all_stopwords.extend(sw_list)\n",
        "\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'football', ',', 'however', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELmWtGUHB-so"
      },
      "source": [
        "The script above adds two words likes and play to the stopwords.word list. In the output, you will not see these two words as shown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7370Tx2cCE9o"
      },
      "source": [
        "###### **Removing Stop Words from Default NLTK Stop Word List**\n",
        "\n",
        "Since stopwords.word('english') is merely a list of items, you can remove items from this list like any other list. The simplest way to do so is via the remove() method. This is helpful for when your application needs a stop word to not be removed. For example, you may need to keep the word not in a sentence to know when a statement is being negated.\n",
        "\n",
        "The following script removes the stop word not from the default list of stop words in NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EPF7nvhB1rO",
        "outputId": "aacd80cd-c967-4f52-9d6f-99d056e87832"
      },
      "source": [
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'however', 'not', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JOt2Ub5CNb4"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmHudjgCUBx"
      },
      "source": [
        "# Stop Word Removal using Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLpq80hIC-O_"
      },
      "source": [
        "The Gensim library is another extremely useful library for removing stop words from a string in Python. All you have to do is to import the remove_stopwords() method from the gensim.parsing.preprocessing module. Next, you need to pass your sentence from which you want to remove stop words, to the remove_stopwords() method which returns text string without the stop words.\n",
        "\n",
        "Let's take a look at a simple example of how to remove stop words via the Gensim library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8FPWUQACV-z",
        "outputId": "f47fa7d9-1074-42e0-bfc2-0a851d8f7aad"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "filtered_sentence = remove_stopwords(text)\n",
        "\n",
        "print(filtered_sentence)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nick likes play football, fond tennis.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3YvlLwZDaw3"
      },
      "source": [
        "It is important to mention that the output after removing stop words using the NLTK and Gensim libraries is different. For example, the Gensim library considered the word however to be a stop word while NLTK did not, and hence didn't remove it. This shows that there is no hard and fast rule as to what a stop word is and what it isn't. It all depends upon the task that you are going to perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17GRK1cQDe9y"
      },
      "source": [
        "## Adding and Removing Stop Words in Default Gensim Stop Words List\n",
        "\n",
        "Let's first take a look at the stop words in Python's Gensim library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdzizWRrDTKS",
        "outputId": "235aac11-7b6f-4fd2-cdc1-a45952ea63e7"
      },
      "source": [
        "import gensim\n",
        "all_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
        "print(all_stopwords)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frozenset({'some', 'becoming', 'have', 'whose', 'never', 'everything', 'eg', 'rather', 'mill', 'together', 'would', 'within', 'is', 'yourselves', 'interest', 'inc', 'via', 'and', 'though', 'behind', 'most', 'who', 'really', 'computer', 'upon', 'give', 'found', 'these', 'among', 'whom', 'own', 'least', 'ever', 'me', 'a', 'well', 'cry', 'be', 'full', 're', 'where', 'that', 'same', 'unless', 'hers', 'regarding', 'for', 'about', 'than', 'fifteen', 'hundred', 'whether', 'she', 'whereafter', 'mine', 'are', 'km', 'even', 'neither', 'whereas', 'your', 'kg', 'to', 'became', 'an', 'latterly', 'sometimes', 'herself', 'us', 'co', 'say', 'ourselves', 'system', 'further', 'we', 'how', 'indeed', 'throughout', 'get', 'you', 'whereupon', 'nothing', 'anywhere', 'see', 'eight', 'i', 'else', 'bill', 'something', 'if', 'perhaps', 'don', 'anyone', 'etc', 'ie', 'might', 'afterwards', 'both', 'front', 'hereafter', 'them', 'various', 'moreover', 'nowhere', 'cant', 'empty', 'done', 'himself', 'amongst', 'amoungst', 'by', 'in', 'other', 'here', 'each', 'anyway', 'several', 'her', 'third', 'formerly', 'often', 'again', 'out', 'made', 'couldnt', 'then', 'ten', 'has', 'ours', 'yet', 'too', 'sincere', 'between', 'almost', 'per', 'move', 'with', 'hereupon', 'had', 'keep', 'before', 'around', 'whoever', 'was', 'serious', 'still', 'part', 'call', 'beside', 'wherein', 'although', 'do', 'everyone', 'first', 'using', 'beyond', 'ltd', 'or', 'up', 'what', 'anyhow', 'enough', 'detail', 'anything', 'someone', 'above', 'two', 'once', 'didn', 'below', 'wherever', 'become', 'very', 'only', 'whenever', 'last', 'hence', 'therein', 'off', 'on', 'nor', 'former', 'sometime', 'should', 'will', 'latter', 'toward', 'because', 'its', 'itself', 'after', 'been', 'make', 'not', 'others', 'take', 'as', 'our', 'none', 'except', 'him', 'quite', 'whatever', 'side', 'de', 'being', 'thick', 'there', 'also', 'few', 'twelve', 'thus', 'they', 'thereupon', 'alone', 'eleven', 'however', 'otherwise', 'mostly', 'whereby', 'go', 'next', 'towards', 'any', 'everywhere', 'did', 'nevertheless', 'myself', 'so', 'but', 'another', 'from', 'always', 'may', 'he', 'while', 'all', 'through', 'no', 'into', 'put', 'without', 'name', 'much', 'un', 'amount', 'either', 'this', 'six', 'could', 'please', 'am', 'already', 'doing', 'nine', 'can', 'three', 'now', 'noone', 'fill', 'under', 'nobody', 'less', 'becomes', 'such', 'just', 'yours', 'until', 'against', 'seeming', 'his', 'hereby', 'it', 'during', 'many', 'over', 'four', 'cannot', 'every', 'besides', 'hasnt', 'yourself', 'forty', 'my', 'thereby', 'beforehand', 'meanwhile', 'thence', 'at', 'show', 'thru', 'when', 'somewhere', 'why', 'sixty', 'whole', 'twenty', 'doesn', 'seemed', 'must', 'one', 'con', 'the', 'describe', 'across', 'since', 'somehow', 'find', 'more', 'due', 'whence', 'onto', 'those', 'elsewhere', 'top', 'herein', 'thin', 'which', 'does', 'bottom', 'back', 'thereafter', 'namely', 'used', 'fify', 'seem', 'five', 'fire', 'their', 'down', 'themselves', 'therefore', 'seems', 'whither', 'along', 'of', 'were'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86Rl5M9aDogi"
      },
      "source": [
        "You can see that Gensim's default collection of stop words is much more detailed, when compared to NLTK. Also, Gensim stores default stop words in a frozen set object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5_JYe6rDyPO"
      },
      "source": [
        "### Adding Stop Words to Default Gensim Stop Words List\n",
        "\n",
        "To access the list of Gensim stop words, you need to import the frozen set STOPWORDS from the gensim.parsing.preprocessong package. A frozen set in Python is a type of set which is immutable. You cannot add or remove elements in a frozen set. Hence, to add an element, you have to apply the union function on the frozen set and pass it the set of new stop words. The union method will return a new set which contains your newly added stop words, as shown below.\n",
        "\n",
        "The following script adds likes and play to the list of stop words in Gensim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o7o5hMqDk_i",
        "outputId": "c9fdb08d-0ac0-41b8-d406-902461cf5d9c"
      },
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "all_stopwords_gensim = STOPWORDS.union(set(['likes', 'play']))\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'football', ',', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb8TCvuZFxHw"
      },
      "source": [
        "From the output above, you can see that the words like and play have been treated as stop words and consequently have been removed from the input sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iup7sAOXFynW"
      },
      "source": [
        "### Removing Stop Words from Default Gensim Stopword List\n",
        "To remove stop words from Gensim's list of stop words, you have to call the difference() method on the frozen set object, which contains the list of stop words. You need to pass a set of stop words that you want to remove from the frozen set to the difference() method. The difference() method returns a set which contains all the stop words except those passed to the difference() method.\n",
        "\n",
        "The following script removes the word not from the set of stop words in Gensim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X1xVZ3LFsj6",
        "outputId": "4e3a89e0-7171-4561-8325-05d6694379ec"
      },
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "all_stopwords_gensim = STOPWORDS\n",
        "sw_list = {\"not\"}\n",
        "all_stopwords_gensim = STOPWORDS.difference(sw_list)\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'not', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0FwcOPUGMVV"
      },
      "source": [
        "Since the word not has now been removed from the stop word set, you can see that it has not been removed from the input sentence after stop word removal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG2sEg86GAAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVXQAXxjGTu4"
      },
      "source": [
        "# Stop Word Removal using SpaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgwSD94VGd92"
      },
      "source": [
        "The SpaCy library in Python is yet another extremely useful language for natural language processing in Python.\n",
        "\n",
        "To install SpaCy, you have to execute the following script on your command terminal:\n",
        "\n",
        "\n",
        "```\n",
        "pip install -U spacy\n",
        "```\n",
        "\n",
        "Once the library is downloaded, you also need to download the language model. Several models exist in SpaCy for different languages. We will be installing the English language model. Execute the following command in your terminal:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python -m spacy download en\n",
        "```\n",
        "\n",
        "\n",
        "Once the language model is downloaded, you can remove stop words from text using SpaCy. Look at the following script:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL5t261CGZLI",
        "outputId": "db90b8e2-5417-4480-b194-792fddcbf9e6"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'fond', 'tennis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dq-EYuyHL99"
      },
      "source": [
        "In the script above we first load the language model and store it in the sp variable. The sp.Default.stop_words is a set of default stop words for English language model in SpaCy. Next, we simply iterate through each word in the input text and if the word exists in the stop word set of the SpaCy language model, the word is removed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJr5Y7PHWcH"
      },
      "source": [
        "## Adding and Removing Stop Words in SpaCy Default Stop Word List\n",
        "\n",
        "Like the other NLP libraries, you can also add or remove stop words from the default stop word list in Spacy. But before that, we will see a list of all the existing stop words in SpaCy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgJguJLbHBTj",
        "outputId": "016c56c7-8b09-4bc8-cc4b-53de064853f3"
      },
      "source": [
        "print(len(all_stopwords))\n",
        "print(all_stopwords)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "326\n",
            "{'some', 'becoming', 'have', 'whose', 'never', 'everything', 'rather', '‘m', 'together', 'within', 'would', \"'ve\", 'fifty', 'is', 'yourselves', 'via', 'and', 'though', 'behind', 'most', 'who', 'really', 'upon', 'give', 'these', 'among', 'whom', 'own', 'least', 'ever', 'me', 'a', 'well', 'be', 'full', 're', 'where', 'that', 'same', 'unless', 'hers', 'for', 'regarding', 'about', 'fifteen', 'hundred', 'than', 'whether', 'she', 'whereafter', 'mine', 'are', 'even', \"n't\", \"'s\", 'neither', 'whereas', 'your', 'became', 'to', 'an', 'latterly', 'sometimes', 'herself', 'us', 'say', 'ourselves', 'further', 'we', 'how', 'indeed', 'throughout', 'get', 'you', 'whereupon', 'nothing', 'anywhere', 'see', 'eight', 'i', 'else', 'something', '’ve', 'if', 'perhaps', 'anyone', 'might', 'afterwards', 'both', 'front', 'hereafter', 'them', 'various', 'moreover', 'nowhere', 'empty', 'amongst', 'done', 'himself', 'by', 'in', '‘d', 'other', 'here', \"'ll\", 'each', 'anyway', 'several', 'her', 'third', 'formerly', 'often', 'again', 'out', 'made', 'then', 'ten', 'has', 'ours', 'yet', 'too', 'between', 'almost', 'per', 'move', 'with', 'hereupon', 'had', 'keep', 'before', 'around', 'serious', 'was', 'whoever', 'still', '’s', 'part', 'call', 'beside', 'wherein', 'although', 'do', 'everyone', 'first', 'using', 'beyond', 'or', \"'d\", 'ca', 'up', 'what', 'anyhow', 'enough', 'anything', 'someone', 'above', 'two', 'once', 'below', '’d', 'wherever', 'become', 'very', 'only', 'whenever', 'hence', 'last', 'therein', 'off', 'on', \"'re\", 'nor', 'former', 'sometime', 'should', 'will', 'latter', '‘re', 'toward', 'because', 'its', 'after', 'itself', 'been', 'make', 'not', 'others', 'take', 'as', 'our', 'none', 'except', 'him', 'quite', 'whatever', 'side', 'being', 'there', 'also', 'few', 'twelve', 'thus', 'they', 'thereupon', 'alone', 'eleven', 'however', 'otherwise', 'mostly', 'whereby', 'go', 'n‘t', 'next', 'towards', 'any', 'everywhere', 'did', 'nevertheless', 'myself', 'so', 'but', 'another', 'from', 'always', 'may', 'he', 'while', 'all', 'through', 'no', 'into', 'put', 'without', 'name', 'much', 'amount', '‘ve', 'either', 'this', 'six', 'could', 'please', 'am', 'already', 'doing', 'nine', 'can', 'three', 'now', 'noone', \"'m\", 'under', 'nobody', 'less', 'becomes', 'such', 'just', 'yours', 'until', 'against', 'seeming', 'his', 'hereby', 'it', 'during', 'many', 'over', 'four', 'cannot', 'every', 'besides', 'yourself', 'n’t', 'forty', 'my', 'thereby', 'beforehand', 'meanwhile', 'thence', 'at', 'show', 'thru', 'when', 'somewhere', 'why', 'sixty', 'whole', 'twenty', 'seemed', 'must', 'one', 'the', 'across', 'since', 'somehow', '‘s', 'more', 'due', 'whence', 'onto', 'those', '’ll', 'elsewhere', 'top', '‘ll', 'herein', 'which', 'does', 'bottom', 'back', 'thereafter', 'namely', 'used', '’re', 'five', 'seem', 'their', 'down', 'themselves', 'therefore', '’m', 'seems', 'whither', 'along', 'of', 'were'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6YrAF0xHgJA"
      },
      "source": [
        "The output shows that there 326 stop words in the default list of stop words in the SpaCy library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bBNXdiUHhNe"
      },
      "source": [
        "### Adding Stop Words to Default SpaCy Stop Words List\n",
        "\n",
        "The SpaCy stop word list is basically a set of strings. You can add a new word to the set like you would add any new item to a set.\n",
        "\n",
        "Look at the following script in which we add the word `tennis` to existing list of stop words in Spacy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH6lScRiHc1c",
        "outputId": "03ea909a-632c-4d32-ead0-dc5fc7f0ae07"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords.add(\"tennis\")\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'likes', 'play', 'football', ',', 'fond', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "354JepGXH0v1"
      },
      "source": [
        "The output shows that the word `tennis` has been removed from the input sentence.\n",
        "\n",
        "You can also add multiple words to the list of stop words in SpaCy as shown below. The following script adds `likes` and `tennis` to the list of stop words in SpaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdN1kCFsHwit",
        "outputId": "d07fc9c7-950c-4cf8-9e23-5b7d13fd2071"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords |= {\"likes\",\"tennis\",}\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'play', 'football', ',', 'fond', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNtgYuKuIPW1"
      },
      "source": [
        "### Removing Stop Words from Default SpaCy Stop Words List\n",
        "To remove a word from the set of stop words in SpaCy, you can pass the word to remove to the `remove` method of the set.\n",
        "\n",
        "The following script removes the word `not` from the set of stop words in SpaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvCCH90yH7De",
        "outputId": "f7c770fd-a686-46ae-dcde-1d36ca6448dd"
      },
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "all_stopwords = sp.Defaults.stop_words\n",
        "all_stopwords.remove('not')\n",
        "\n",
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "text_tokens = word_tokenize(text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
        "\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nick', 'play', 'football', ',', 'not', 'fond', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbZ7zh3pIiKD"
      },
      "source": [
        "In the output, you can see that the word not has not been removed from the input sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dia_cUErIdGn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEpcFjfGIpYH"
      },
      "source": [
        "# Using Custom Script to Remove Stop Words\n",
        "\n",
        "Till now, we saw how we can use various libraries to remove stop words from a string in Python. If you want full control over stop word removal, you can write your own script to remove stop words from your string.\n",
        "\n",
        "The first step in this regard is to define a list of words that you want treated as stop words. Let's create a list of some of the most commonly used stop words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxpCWyRsIy_q"
      },
      "source": [
        "my_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHt_v1hmI_MU"
      },
      "source": [
        "Next, we will define a function that will accept a string as a parameter and will return the sentence without the stop words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2AiNiVdI6da"
      },
      "source": [
        "def remove_mystopwords(sentence):\n",
        "    tokens = sentence.split(\" \")\n",
        "    tokens_filtered= [word for word in text_tokens if not word in my_stopwords]\n",
        "    return (\" \").join(tokens_filtered)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH7FhgRfJNM3"
      },
      "source": [
        "Let's now try to remove stop words from a sample sentence:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFPNSbpJJD-b",
        "outputId": "3cace9e4-38fd-42c5-8fe7-f22d7fcd013d"
      },
      "source": [
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "filtered_text = remove_mystopwords(text)\n",
        "print(filtered_text)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nick likes play football , however fond tennis .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spTQ1QnWJVA6"
      },
      "source": [
        "You can see that stop words that exist in the my_stopwords list has been removed from the input sentence.\n",
        "\n",
        "Since my_stopwords list is a simple list of strings, you can add or remove words into it using simple \n",
        "\n",
        "\n",
        "```\n",
        "# To add to list\n",
        "my_stopwords.append(\"football\")\n",
        "\n",
        "# To remove from list\n",
        "my_stopwords.remove(\"football\")\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD0Ws5plJN24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}