# About:

In this chapter, we will learn:

1. How to use tokenizers and models to replicate the pipeline APIâ€™s behavior
2. How to load and save models and tokenizers
3. Different tokenization approaches, such as word-based, character-based, and subword-based
4. How to handle multiple sentences of varying lengths

## Sequence:

1. [**Transformer Pipeline Readme**](https://github.com/mittalsharad/NLP/blob/main/HuggingFace/Ch%202.%20Using%20Transformer/Transformer%20Pipeline.md) : Detail view of a Pipeline
2. [**Transfor Pipeline Notebook**](https://github.com/mittalsharad/NLP/blob/main/HuggingFace/Ch%202.%20Using%20Transformer/Transformer_Pipeline.ipynb) : Pratical implementation of the detailed view
3. [**Creating_Transformer**](https://github.com/mittalsharad/NLP/blob/main/HuggingFace/Ch%202.%20Using%20Transformer/Creating_Transformer.ipynb) : Creating and using Transformer Model using Hugging Face
4. [**Tokenizers(PyTorch)**](https://github.com/mittalsharad/NLP/blob/main/HuggingFace/Ch%202.%20Using%20Transformer/Tokenizers(PyTorch).ipynb) : Details of what happens in a Tokenizer pipeline
